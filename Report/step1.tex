The main aim of the environment is to simulate a real-world scenario. To simulate all the components we divide the model into various classes.
\begin{itemize}
    \item Environment class: It is the wrapper that manages the environment and all its functions. There are two specializations of this class created for some specific use cases (which are EnvironmentContextual and EnvironmentNonStationary).
    \item Simulator class: It manages the simulation of the customers' interactions.
    \item Customer class: It contains all the information that defines a type of customer.
\end{itemize}

\subsection{Parameters}
The environment has a lot of parameters and each of them has a direct and significant impact on the behavior of the model.
Some of the parameters are specifics of the environment:
\begin{itemize}
  \item \verb|customers_distribution| is a list of 4 floating values, that sum to 1. It indicates the probability of each type of customer appearing.
  \item \verb|customer_per_day| is the average number of customers in a day.
  \item \verb|variance_customers| is the standard deviation of the number of customers in a day.
  \item \verb|products_graph| is the graph that indicates which is the primary and secondary product.
  \item \verb|p_lambda| is the probability of observing each slot. The first value is 1, while the second is a number smaller than 1.
  \item \verb|prices| indicates the reward for each product and each price level. Therefore, it is a 4 x 5 matrix.
\end{itemize}
Additionally, some parameters are specifics of the customer:
\begin{itemize}
    \item \verb|features| is the pair of binary features. In our case, the first feature is associated with gender whereas the second one with the age (for simplicity young/old).
    \item \verb|alpha| is a vector that contains the probability distribution of starting from each product.
    \item \verb|buy_distribution| is a matrix containing for each pair (product, price) that defines the probability of buying products.
    \item \verb|num_prods_distribution| is a matrix containing for each pair (product, price), and it controls the number of units the customer is likely to buy for that specific product. In this case, we have decided to model the customer's behavior with a geometric distribution. Thus, they are the \(p\) parameters of the geometric distributions, which is the inverse of the means.
    The main idea behind the geometric distribution is that is a discrete distribution and is monotonically decreasing: the higher the number of products bought, the lower will be the probability to buy that amount of units.
    \item \verb|click_graph| is the probability of clicking the product given a selected price and type of product.
\end{itemize}

\subsection{Learner interaction}
The main aim of the learner is to minimize the cumulative regret by selecting the best price levels.
Therefore, at the beginning of each day, the learner selects the price levels (which is the super arm), and then at the end of the day, it will obtain a report containing all the information about the customer activities, i.e. number of times bought, number of products seen, number of customers.


\subsection{Customer interaction}
The customer interaction works in the following manner:
\begin{enumerate}
    \item Depending on the \verb|alpha| distribution a starting point is randomly chosen.
    \item The customer opens the page and she will buy one or more products with a probability depending on \verb|buy_distribution|. If she does not buy the simulation stops, otherwise the number of items bought is sampled from a geometrical distribution.
    \item Then, with a probability that depends on \(\lambda\) and the \verb|click_graph|, she explores a different product. However, if she has already seen this product, she will not open that page.
\end{enumerate}

From step 3 to step 6 the main assumption is that we have different classes of customers interacting with the website, and each of them has a different behavior. For each step, we know the distribution of the customers and some characteristics of them (for instance the mean of the number of items a customer buys for a specific product), but the website is not able to identify the customer is interacting with it, thus we are not able to estimate the unknown parameters for each customer but only an aggregated estimate.

\subsection{Selection of the super arm}
Since we have to take into consideration also the indirect income generated by other products that are bought after buying the first product, we have to find the combination of prices such that it maximizes the overall income considering the indirect margins, thus we have to solve a combinatorial problem to select the best super arm to play.\\
In order to do so, we have to compute the believed expected reward $\EX\left[ r_a\right]$ for each superarm $a$ and choose the arm with the highest expected reward. We compute the expected reward as follows:
\begin{align*}
    \EX\left[ r_a\right] = \sum_{i \in \mathcal{C}} r_{a,i} w_i
\end{align*}
where $\mathcal{C}$ is the set of indexes of customers, $r_{a,i}$ is the expected reward given the super arm $a$ for customer $i$ and $w_i$ is the probability to see customer $i$.\\
\subsubsection{Monte Carlo methods}
A way to compute the expected reward for a given customer $i$ is to use a Monte Carlo simulation.\\ Monte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle.\\ Basically, we have 5 seeds (the products) and we run $N$ simulations starting from each seed.
A seed is a starting node in a graph, whose edges $e_{i, j}$ represent the probability of clicking product $j$ given that product $i$ has been bought, whereas each node has an activation threshold that coincides with the probability of buying that product.\\
The simulation works as follows:
\begin{enumerate}
    \item Explore the simulation graph in a depth first search tree fashion. If a node has been already visited, it can not be reached anymore.
    \item When selecting a node $j$, draw a sample $x$ from a Bernoulli distribution  $\mathcal{B}e(t_{i, p, j})$ where $t_{i, p, j}$ is the probability that customer $i$ buys product $j$ at price $p$. If $x < t_{i, p, j}$, activate node $j$, otherwise stop the branch.\\ We can keep track of the number of times a node $j$ has been activated with the variable $\Lambda_j$.
    \item When expanding an active node $i$ towards node $j$, draw a sample $x$ from a Bernoulli distribution $\mathcal{B}e(e_{i, j})$. If $x < e_{i, j}$ move towards node $j$, otherwise stop the branch.
\end{enumerate}
Once a node is activated we draw a sample $n$ from the distribution of the number of items bought for that node (product). Every time a product is bought, we update the number of times that product has been bought:
\begin{align*}
    n_{a, p} = n_{a, p} + n
\end{align*}
where $n_{a, p}$ is the current number of units bought for product $p$ given the super arm $a$.\\
Here, the code for a single simulation:\\
\begin{minted}[breaklines]{python}
def shopping_dfs(self, primary, displayed_primary, report, super_arm, c):
  displayed_primary[primary] = True
  report.seen(primary)
  if np.random.random() < c.get_probability_buy(primary, super_arm[primary]):
    amount = c.get_num_prods(primary, super_arm[primary]) #1
    report.bought(primary, amount)
    click_prob = [c.get_probability_click(primary, secondary) for secondary in self.products_graph[primary]]
    for secondary, edge_prob, lamb in zip(self.products_graph[primary], click_prob, lamb_SLOTS):
      if not displayed_primary[secondary] and np.random.random() < lamb * edge_prob:
        report.move(primary, secondary)
        self.shopping_dfs(secondary, displayed_primary, report, super_arm, c)
\end{minted}
Finally, we compute the expected reward as:
\begin{align*}
    r_{a, i} = \frac{1}{N}\sum_{p \in \mathcal{P}}\alpha_{i, p} a_{p} n_{a, p}
\end{align*}
where $\mathcal{P}$ is the set of indexes of the products, $\alpha_{i, p}$ is the probability for customer $i$ to start from the seed $p$ and $a_{p}$ is the price selected for the product $p$. We can also compute the activation probability (probability that a specific item is bought) of each product as:
\begin{align*}
    \pi_{p, i} = \frac{1}{N}\sum_{p \in \mathcal{P}}\alpha_{i, p} \Lambda_p
\end{align*}
Thanks to the following theorem we have some theoretical guarantees on the accuracy of this method.
\paragraph{Theorem}
With a probability of at least $1 - \delta$, the estimated activation probability of every node is subject to an additive error of $\pm \epsilon n$ when the number of repetitions is:
\begin{align*}
    R = O(\frac{1}{\epsilon^2}log(\mid S \mid)log(\frac{1}{\delta}))
\end{align*}
where $S$ is the number of seeds (5) and $n$ is the number of nodes in the graph (still 5).\\

In our case, if we want to have an additive error of $\epsilon n = 0.1$ ($\epsilon = 0.02$) with a probability of 90 \% ($\delta=0.1$), we need to run $R=1748$, thus the number of simulations for each product for each customer is $N=350$.
In conclusion, this method is stochastic and very noisy, and to obtain a decent estimate we need to run a massive number of simulations which makes the simulation process astonishingly slow.\\
Given the size of the parameters for this problem, we can afford to compute the exact value for the expected value for a given arm in a reasonable time with a different approach.

\subsubsection{Dynamic programming approach}
To overcome the limitation of the Monte Carlo simulation we develop a dynamic programming solution that returns the expected number of items bought. This method has a time complexity of \(\Theta(2^{N}NM)\), where \(N\) is the number of items and \(M\) is the number of types of customers, therefore, this solution is only feasible because the number of items is quite small.
\begin{minted}[breaklines]{python}
def run_dp(self, super_arm):
  ans = 0
  for c, p in zip(self.customers, self.customers_distribution):
    @lru_cache(maxsize=None)
    def dp(primary, mask):
      mask |= 1 << primary
      ans = np.zeros(5)
      ans[primary] = 1 / c.num_prods_distributions[primary][super_arm[primary]]
      click_prob = [c.get_probability_click(primary, secondary) for secondary in self.products_graph[primary]]
      for secondary, edge_prob, lamb in zip(self.products_graph[primary], click_prob, lamb_SLOTS):
        if (mask & (1 << secondary)) == 0:
          ans += lamb * edge_prob * dp(secondary, mask)
      ans *= c.get_probability_buy(primary, super_arm[primary])
      return ans
    for primary, alpha in enumerate(c.get_distribution_alpha()):
      ans += p * alpha * dp(primary, 0)
  return ans
\end{minted}
\subsection{Assumptions}
In this section we list the main assumptions we undertook to face this problem:
\begin{itemize}
    \item for simplicity we assume that the value $\lambda$ for the second displayed product is equal to 1 without loss of generality.
    \item The probability $\alpha_0$ which is the probability to land on another website is omitted, since it does not add any additional feature to the problem.
    \item Customers, accordingly to their behaviour can be grouped into three classes:
    \begin{enumerate}
        \item Boys
        \item Girls
        \item Adults
    \end{enumerate}
    Note: this is just an assumption used to model the customer of the environment, the learner is not acknowledged about this assumption.
\end{itemize}
